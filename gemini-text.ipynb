{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP1aYoUBmG9QSXo7CcioCbK"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jvfbQnpcfZqU","executionInfo":{"status":"ok","timestamp":1715750174152,"user_tz":-330,"elapsed":23488,"user":{"displayName":"Omkar Dhariya","userId":"15105095125063966773"}},"outputId":"c99407a3-c59b-4fe3-b104-a1148df951a0"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/150.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[32m143.4/150.7 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.7/150.7 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/677.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m677.8/677.8 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}],"source":["!pip install -q -U google-generativeai"]},{"cell_type":"code","source":["import pathlib\n","import textwrap\n","\n","import google.generativeai as genai\n","\n","# Used to securely store your API key\n","from google.colab import userdata\n","\n","from IPython.display import display\n","from IPython.display import Markdown\n","\n","\n","def to_markdown(text):\n","  text = text.replace('•', '  *')\n","  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))"],"metadata":{"id":"IA8R3HnmfkQM","executionInfo":{"status":"ok","timestamp":1715750174795,"user_tz":-330,"elapsed":651,"user":{"displayName":"Omkar Dhariya","userId":"15105095125063966773"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# Or use `os.getenv('GOOGLE_API_KEY')` to fetch an environment variable.\n","# GOOGLE_API_KEY=\"AIzaSyDeZgZ84gXnZUjT5-HugjeryWegAzmvCZQ\" #userdata.get('GOOGLE_API_KEY')\n","# GOOGLE_API_KEY=\"AIzaSyCyVU6urXoERjYdY1gJ5gNhWik-YeoqJuY\"\n","# GOOGLE_API_KEY=\"AIzaSyDiaD8f0zdyBS0GR2ryQbNuGPpO_Cjpsuc\" #r92\n","GOOGLE_API_KEY=\"AIzaSyDoqVfKPBz_XuGa9AA5FmZnz7IV0qe9gpg\" #company1\n","\n","genai.configure(api_key=GOOGLE_API_KEY)"],"metadata":{"id":"FnoDZTmjfmCP","executionInfo":{"status":"ok","timestamp":1715750174795,"user_tz":-330,"elapsed":5,"user":{"displayName":"Omkar Dhariya","userId":"15105095125063966773"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["for m in genai.list_models():\n","  # if 'generateContent' in m.supported_generation_methods:\n","    print(m.name)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":267},"id":"MjlHUXKpgW3q","executionInfo":{"status":"ok","timestamp":1715750177995,"user_tz":-330,"elapsed":3204,"user":{"displayName":"Omkar Dhariya","userId":"15105095125063966773"}},"outputId":"b8115615-807c-44c1-c8d4-0827af73e747"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["models/chat-bison-001\n","models/text-bison-001\n","models/embedding-gecko-001\n","models/gemini-1.0-pro\n","models/gemini-1.0-pro-001\n","models/gemini-1.0-pro-latest\n","models/gemini-1.0-pro-vision-latest\n","models/gemini-1.5-flash-latest\n","models/gemini-1.5-pro-latest\n","models/gemini-pro\n","models/gemini-pro-vision\n","models/embedding-001\n","models/text-embedding-004\n","models/aqa\n"]}]},{"cell_type":"code","source":["model = genai.GenerativeModel('gemini-1.5-pro-latest')"],"metadata":{"id":"oJTasWfYDleq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%time\n","response = model.generate_content(\"Are you using gemini-pro-1.0 or gemini pro 1.5?\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":53},"id":"FzwDcIv4gYqy","executionInfo":{"status":"ok","timestamp":1712820491564,"user_tz":-330,"elapsed":4637,"user":{"displayName":"Omkar Dhariya","userId":"15105095125063966773"}},"outputId":"4ca449d6-70ad-4afa-aaf5-992663e28038"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["CPU times: user 47.1 ms, sys: 7.68 ms, total: 54.8 ms\n","Wall time: 4.63 s\n"]}]},{"cell_type":"code","source":["to_markdown(response.text)\n"],"metadata":{"id":"7Gm9tOrMhgG4","colab":{"base_uri":"https://localhost:8080/","height":80},"executionInfo":{"status":"ok","timestamp":1712820500041,"user_tz":-330,"elapsed":8,"user":{"displayName":"Omkar Dhariya","userId":"15105095125063966773"}},"outputId":"63caf212-da16-4f03-9808-c569cc5695d2"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"> As a large language model, I don't have access to information about the specific model versions or internal infrastructure of Google AI. My primary function is to process and generate text, translate languages, write different kinds of creative content, and answer your questions in an informative way. \n"},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":[],"metadata":{"id":"w06Rl7BYDrIm"},"execution_count":null,"outputs":[]}]}