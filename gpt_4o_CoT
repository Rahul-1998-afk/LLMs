{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1SNM_o8Q-hsWcPCPMGNlRiGT8YWPj_FrY","authorship_tag":"ABX9TyPEIPDrP+w+Bhj9hfPGV8Pn"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":9,"metadata":{"id":"cmI8K7JPFJts","executionInfo":{"status":"ok","timestamp":1721932442051,"user_tz":-330,"elapsed":6729,"user":{"displayName":"Omkar Dhariya","userId":"15105095125063966773"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"0ce3e177-0d94-4826-a931-d1faac9e1d16"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting faiss-cpu\n","  Downloading faiss_cpu-1.8.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.7 kB)\n","Requirement already satisfied: numpy<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (1.25.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (24.1)\n","Downloading faiss_cpu-1.8.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.0/27.0 MB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: faiss-cpu\n","Successfully installed faiss-cpu-1.8.0.post1\n"]}],"source":["# !pip install openai\n","# !pip install tiktoken\n","# !pip install langchain-openai\n","# !pip install langchain_experimental\n","# !pip install langchain-google-genai\n","!pip install faiss-cpu"]},{"cell_type":"code","source":["import openai as ai\n","import re\n","import tiktoken\n","import pandas as pd\n","import json"],"metadata":{"id":"j9woXBmjgt2M","executionInfo":{"status":"ok","timestamp":1721934136962,"user_tz":-330,"elapsed":593,"user":{"displayName":"Omkar Dhariya","userId":"15105095125063966773"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["from pathlib import Path\n","\n","import pandas as pd\n","from langchain.agents import AgentExecutor, OpenAIFunctionsAgent\n","from langchain.tools.retriever import create_retriever_tool\n","from langchain_community.chat_models import ChatOpenAI\n","from langchain_community.embeddings import OpenAIEmbeddings\n","from langchain_community.vectorstores import FAISS\n","from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n","from langchain_core.pydantic_v1 import BaseModel, Field\n","from langchain_experimental.tools import PythonAstREPLTool\n","\n","import os\n","openai_api_key = \"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\"#os.environ[\"OPENAI_API_KEY\"]\n","os.environ[\"OPENAI_API_KEY\"] = openai_api_key"],"metadata":{"id":"ZvqjuAZam7CS","executionInfo":{"status":"ok","timestamp":1721934137634,"user_tz":-330,"elapsed":5,"user":{"displayName":"Omkar Dhariya","userId":"15105095125063966773"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["openai_api_key=\"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\"\n","ai.api_key = openai_api_key\n","\n","def chat_completion_ai(message, model=\"gpt-4o\", openai_api_key=None, max_length=1000):\n","  try:\n","    ## TODO find max length issue\n","    response = ai.chat.completions.create(\n","        model=model,\n","        messages=message,\n","        max_tokens=max_length,  # default max length of output is 100\n","        temperature=0\n","    )\n","\n","    output = ''\n","    for choice in response.choices:\n","        output += choice.message.content.strip(\"/n\")\n","\n","    # log_obj.info(\"OpenAI results: \" + str(output))\n","\n","    return output\n","  except:\n","    import traceback as tb\n","    tb.print_exc()\n"],"metadata":{"id":"HnA_YYw1h7xx","executionInfo":{"status":"ok","timestamp":1721934137634,"user_tz":-330,"elapsed":3,"user":{"displayName":"Omkar Dhariya","userId":"15105095125063966773"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["# MAIN_DIR = Path(__file__).parents[1]\n","\n","pd.set_option(\"display.max_rows\", 20)\n","pd.set_option(\"display.max_columns\", 20)\n","\n","# # Retriver tool\n","# embedding_model = OpenAIEmbeddings()\n","# vectorstore = FAISS.load_local(\"./\", embedding_model, allow_dangerous_deserialization=True)\n","# retriever_tool = create_retriever_tool(\n","#     vectorstore.as_retriever(), \"person_name_search\", \"Search for a person by name\"\n","# )\n","\n","\n","TEMPLATE = \"\"\"You are working with a pandas dataframe in Python. The name of the dataframe is `df`.\n","It is important to understand the attributes of the dataframe before working with it. This is the result of running `df.head().to_markdown()`\n","\n","<df>\n","{dhead}\n","</df>\n","\n","You are not meant to use only these rows to answer questions - they are meant as a way of telling you about the shape and schema of the dataframe.\n","You also do not have use only the information here to answer questions - you can run intermediate queries to do exporatory data analysis to give you more information as needed.\n","\n","You have a tool called `person_name_search` through which you can lookup a person by name and find the records corresponding to people with similar name as the query.\n","You should only really use this if your search term contains a persons name. Otherwise, try to solve it with code.\n","\n","For example:\n","<question>Who has id 320</question>\n","<logic>Use `python_repl` since even though the question is about a person, you don't know their name so you can't include it.</logic>\n","\"\"\"  # noqa: E501\n","\n","\n","class PythonInputs(BaseModel):\n","    query: str = Field(description=\"code snippet to run\")\n","\n","path = \"/content/drive/MyDrive/Colab Notebooks/LLM/amzon-Q&A/data/electronic_products.csv\"\n","df = pd.read_csv(path)\n","template = TEMPLATE.format(dhead=df.head().to_markdown())\n","\n","prompt = ChatPromptTemplate.from_messages(\n","    [\n","        (\"system\", template),\n","        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n","        (\"human\", \"{input}\"),\n","    ]\n",")\n","\n","repl = PythonAstREPLTool(\n","    locals={\"df\": df},\n","    name=\"python_repl\",\n","    description=\"Runs code and returns the output of the final line\",\n","    args_schema=PythonInputs,\n",")\n","tools = [repl]\n","agent = OpenAIFunctionsAgent(\n","    llm=ChatOpenAI(temperature=0, model=\"gpt-4\"), prompt=prompt, tools=tools\n",")\n","agent_executor = AgentExecutor(\n","    agent=agent, tools=tools, max_iterations=5, early_stopping_method=\"generate\"\n",") | (lambda x: x[\"output\"])\n","\n","# Typing for playground inputs\n","\n","\n","class AgentInputs(BaseModel):\n","    input: str\n","\n","\n","agent_executor = agent_executor.with_types(input_type=AgentInputs)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rJQLpm-Ym2wP","executionInfo":{"status":"ok","timestamp":1721934140825,"user_tz":-330,"elapsed":1687,"user":{"displayName":"Omkar Dhariya","userId":"15105095125063966773"}},"outputId":"8150e324-ade7-4961-fcec-476dc5d88fb0"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n","  warn_deprecated(\n","/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The class `OpenAIFunctionsAgent` was deprecated in LangChain 0.1.0 and will be removed in 0.3.0. Use create_openai_functions_agent instead.\n","  warn_deprecated(\n"]}]},{"cell_type":"code","source":["\n","## Ques on the rating column Note: All answers matching perfer default one\n","ques=[\"How many products are there?\",\n","      \"Which product got most of review?\",\n","      \"Give me product wise avg rating\",\n","      \"Which product got highest average rating?\",\n","      \"Which product got lowest average rating?\"]\n","\n","# Que on Date Note: Need to combine both as sometime values store in varibale and answer mention variable\n","# ques=[\"How many total review gate between 01-01-2021 to 01-12-2021\",\n","#       \"How many reviews in 2021\",\n","#       \"Which is most review product in 2022?\",\n","#       \"Which product got average lowest rating in 2023?\",\n","#       \"Product wise avg raiting for year 2022 and 2023\",\n","#       \"Give me the total number of reviews yearwise\",\n","#       \"Predict number of reviews in 2024\",\n","#       \"Give me the avergage rating for camera each year\",\n","#       \"Predict the average rating of camera for 2024\"]\n","\n","# Que on review filtering\n","# ques = [\"Give summary of reviews on camera\",\n","#         \"What most issue mention in laptop\",\n","#         \"What are the positive reviews about laptop\",\n","#         \"List all strghnts about camera\",\n","#         \"List all major issue face by users in camera\"]"],"metadata":{"id":"x8UIosnLpZ-Z","executionInfo":{"status":"aborted","timestamp":1721931270531,"user_tz":-330,"elapsed":6,"user":{"displayName":"Omkar Dhariya","userId":"15105095125063966773"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for question in ques:\n","  # question = \"How many products are there?\"\n","  print(question)\n","  print(agent_executor.invoke({\"input\": question}))\n","  print(\"*\"*10)"],"metadata":{"id":"Rczzvf9qpD8m","executionInfo":{"status":"aborted","timestamp":1721931270531,"user_tz":-330,"elapsed":6,"user":{"displayName":"Omkar Dhariya","userId":"15105095125063966773"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"YZKBANLcpUQZ","executionInfo":{"status":"aborted","timestamp":1721931270531,"user_tz":-330,"elapsed":5,"user":{"displayName":"Omkar Dhariya","userId":"15105095125063966773"}}},"execution_count":null,"outputs":[]}]}